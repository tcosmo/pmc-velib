\documentclass[a4paper, 11pt]{article}
 
\usepackage{ucs}
\usepackage[utf8x]{inputenc}
\usepackage{graphicx}
\usepackage[frenchb]{babel}
 
\begin{document}
 
\title{Dossier de TIPE}
\author{Camille Chanial, Tristan Du Castel, \text{Tristan Stérin}}
\date{05/06/2014} 
 
\maketitle

\abstract{C'est soin taii} 
 
\tableofcontents
 

\newpage

\section*{Introduction : position du problème}
\addcontentsline{toc}{section}{Introduction : position du problème}

\section{La justification mathématiques}
\section{L'algorithme de rétropropagation}

\subsection{Réaliser l'apprentissage : comment minimiser l'erreur, quelle erreur ?}

On a donc vu que les réseaux de neurones présentent un modèle pertinent dans le cadre de la régression non linéaire.\\
Il faut désormais mettre en place l'algorithme qui va permettre de trouver, d'apprendre, la combinaison de poids optimales afin de réaliser l'approximation désirée.\\
On se donne une base d'apprentissage :

$$\matcal{B} = \{(p_1,q_1), \dots, (p_n, q_n)\} \quad \text{ avec : } \quad (p_i,q_i) \in \matcal{A}^a \times \matcal{B}^b$$

Où $\matcal{A}$ et $\matcal{B}$ sont les espaces de départ et d'arrivée et $a$ et $b$ leur dimension respective.\\
Si on note $f:\matcal{A}\to \matcal{B}$ la fonction du réseau (variable au cours de l'apprentissage), notre but est d'avoir un algorithme tel qu'en un nombre fini d'itérations :

$$ \forall i, \quad f(p_i) = q_i $$

On va procéder à cet apprentissage par cycle de présentation de tous les couples de la base au réseau.\\
Lors d'un cycle, on présente chaque couple au réseau, pour le ième couple on calcule le vecteur erreur instantanée $\vec{e} = q_i-f(p_i)$.\\
On se donne comme critère de "bon apprentissage" de notre réseau, comme indice de performance l'erreur quadratique moyenne :

$$ F(p_i)  = E[\,^t  \vec{e} * \vec{e}]$$

L'espérance en question n'étant pas calculable a priori, on l'approxime l'indice de performance par l'erreur instantanée :

$$  \hat{F}(p_i) = ^t \vec{e}*\vec{e}$$

Ainsi notre but est de miniser la fonction $ \hat{F} $.
On utilise pour cela la méthode de descente de gradient telle que : \\

$$ 
	\Delta \omega^{k}_{i,j} = -\etha \frac{\partial \hat{F}}{\partial \omega^{k}_{i,j}}
$$

Avec $ \omega^{k}_{i,j}$ le $j^{\text{ième}}$ poids du $i^{\text{ième}}$ neurone de la $k^{\text{ième}}$ couche, $\eta$ le taux d'apprentissage.\\
Le sujet de cet exposé n'étant pas la descente de gradient, on introduira très briévement à l'oral les notions permettant de comprendre la suite.\\
Calculer les dérivées partielles de $\hat{F}$ n'est pas un problème simple.
\\ On expliquera à l'oral les principales étapes de ce calcul.
\\ On donne ici uniquement l'expression final qui jsutifie l'algorithme proposé par la suite.

\\ On introduit une quantité intermédiraire appelée sensibilité, associée à chaque couche, définie vectoriellement par : 

$$ s^k = \frac{\partial \hat{F} }{\partial{n^k}}$$
$s^k$ est la sensibilité de la couche $k$, et $n^k$ le vecteur des niveaux d'activation de la $k^{\text{ième}}$ couche.
\\
\noident On a : $\Delta W^k = -\eta s^k * \,^t a^{k-1}$
\\ Avec $W^k$ la matrice des poids de la $k^{\text{ième}}$ couche et $a^k$ le vecteur sortie de la $k^{\text{ième}}$ couche.
\\Les sensibilités se calculent par récurrence (on ne donne pas la formule ici, on en parlera cependant à l'oral) d'où le nom de \emph{back propagation} : l'information doit se transmettre de la dernière couche vers la première pour calculer les sensibilités et non pas juste de la première vers la dernière comme lorsqu'on calcule la sortie associée à une entrée.

\subsection{L'algorithme d'entraînement}

\\ L'algorithme d'entraînement est donc le suivant : 

\begin{enumerate}

\item Initialiser tous les poids du réseau à des valeurs aléatoires.
\item Pour chaque association $(p_i,q_i)$ dans la base d’apprentissage:
\begin{itemize}
	\item Propager les entrées $p_i$ vers l'avant
	\item Rétropropager les sensibilités
	\item Mettre à jour les poids
\end{itemize}
\item Si le critère d'arrêt est atteint, stop
\item Recommencer à l'étape 2
\end{enumerate}


\\On appelle perceptron multicouche un réseau de neurones capable de réaliser un apprentissage à travers des algorithmes comparables (parfois plus subtils) à celui de \emph{back-propagation} proposé ici.

\\De très nombreuses questions pratiques se posent alors : quel critère d'arrêt prendre ? Comment initialiser le réseau ? Comment adapter les entrées aux fonctions de transfert, ici principalement sigmoïde ?
\\Ces questions sont traitées dans la partie suivante.

\section{L'application pratique : aspects techniques et résultats}

\subsection{Considérations pratiques quant à l'apprentissage}
	\subsubsection{Entraîner le réseau}
	\subsubsection{Quelques mots d'implémentation}
\subsection{Application : le problème des vélibs}
	\subsubsection{Le data-mining et la base de données}
	\subsubsection{Définition du perceptron utilisé}
\subsection{Analyse des résultats}
	\subsubsection{Résultats}
	\subsubsection{Limites et potentialités}
	
 
\end{document}